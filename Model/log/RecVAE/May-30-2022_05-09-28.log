Mon 30 May 2022 05:09:28 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = dataset/whiskey_with_taste
checkpoint_dir = model_saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 300
train_batch_size = 64
learner = adam
learning_rate = 0.001
neg_sampling = {'popularity': 10}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}
repeatable = False
metrics = ['Recall', 'NDCG']
topk = [5, 10]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 256
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user
ITEM_ID_FIELD = whiskey
RATING_FIELD = rating
TIME_FIELD = None
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user', 'whiskey', 'rating']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = {'rating': '[0,100]'}
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
wandb_project = recbole_whiskey
require_pow = False
hidden_dimension = 600
latent_dimension = 200
dropout_prob = 0.5
beta = 0.2
mixture_weights = [0.15, 0.75, 0.1]
gamma = 0.005
n_enc_epochs = 3
n_dec_epochs = 1
MODEL_TYPE = ModelType.GENERAL
MODEL_INPUT_TYPE = InputType.PAIRWISE
eval_type = EvaluatorType.RANKING
device = cpu
train_neg_sample_args = {'strategy': 'by', 'by': 10, 'distribution': 'popularity', 'dynamic': 'none'}
eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}


Mon 30 May 2022 05:09:29 INFO  whiskey_with_taste
The number of users: 12156
Average actions of users: 7.153681612505142
The number of items: 638
Average actions of items: 136.5039246467818
The number of inters: 86953
The sparsity of the dataset: 98.87882552935146%
Remain Fields: ['user', 'whiskey', 'rating']
Mon 30 May 2022 05:09:29 INFO  [Training]: train_batch_size = [64] negative sampling: [{'popularity': 10}]
Mon 30 May 2022 05:09:29 INFO  [Evaluation]: eval_batch_size = [256] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]
Mon 30 May 2022 05:09:29 WARNING  Max value of user's history interaction records has reached 23.824451410658305% of the total.
Mon 30 May 2022 05:09:29 INFO  RecVAE(
  (encoder): Encoder(
    (fc1): Linear(in_features=638, out_features=600, bias=True)
    (ln1): LayerNorm((600,), eps=0.1, elementwise_affine=True)
    (fc2): Linear(in_features=600, out_features=600, bias=True)
    (ln2): LayerNorm((600,), eps=0.1, elementwise_affine=True)
    (fc3): Linear(in_features=600, out_features=600, bias=True)
    (ln3): LayerNorm((600,), eps=0.1, elementwise_affine=True)
    (fc4): Linear(in_features=600, out_features=600, bias=True)
    (ln4): LayerNorm((600,), eps=0.1, elementwise_affine=True)
    (fc5): Linear(in_features=600, out_features=600, bias=True)
    (ln5): LayerNorm((600,), eps=0.1, elementwise_affine=True)
    (fc_mu): Linear(in_features=600, out_features=200, bias=True)
    (fc_logvar): Linear(in_features=600, out_features=200, bias=True)
  )
  (prior): CompositePrior(
    (encoder_old): Encoder(
      (fc1): Linear(in_features=638, out_features=600, bias=True)
      (ln1): LayerNorm((600,), eps=0.1, elementwise_affine=True)
      (fc2): Linear(in_features=600, out_features=600, bias=True)
      (ln2): LayerNorm((600,), eps=0.1, elementwise_affine=True)
      (fc3): Linear(in_features=600, out_features=600, bias=True)
      (ln3): LayerNorm((600,), eps=0.1, elementwise_affine=True)
      (fc4): Linear(in_features=600, out_features=600, bias=True)
      (ln4): LayerNorm((600,), eps=0.1, elementwise_affine=True)
      (fc5): Linear(in_features=600, out_features=600, bias=True)
      (ln5): LayerNorm((600,), eps=0.1, elementwise_affine=True)
      (fc_mu): Linear(in_features=600, out_features=200, bias=True)
      (fc_logvar): Linear(in_features=600, out_features=200, bias=True)
    )
  )
  (decoder): Linear(in_features=200, out_features=638, bias=True)
)
Trainable parameters: 2200438
Mon 30 May 2022 05:11:00 INFO  epoch 0 training [time: 90.65s, train loss: 2418.3263]
Mon 30 May 2022 05:11:48 INFO  epoch 0 evaluating [time: 48.10s, valid_score: 0.248100]
Mon 30 May 2022 05:11:48 INFO  valid result: 
recall@5 : 0.2976    recall@10 : 0.3483    ndcg@5 : 0.2315    ndcg@10 : 0.2481
Mon 30 May 2022 05:11:48 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:13:13 INFO  epoch 1 training [time: 84.72s, train loss: 2175.8914]
Mon 30 May 2022 05:13:57 INFO  epoch 1 evaluating [time: 43.79s, valid_score: 0.268600]
Mon 30 May 2022 05:13:57 INFO  valid result: 
recall@5 : 0.321    recall@10 : 0.3763    ndcg@5 : 0.2504    ndcg@10 : 0.2686
Mon 30 May 2022 05:13:57 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:15:27 INFO  epoch 2 training [time: 90.55s, train loss: 2091.4361]
Mon 30 May 2022 05:16:08 INFO  epoch 2 evaluating [time: 40.64s, valid_score: 0.272300]
Mon 30 May 2022 05:16:08 INFO  valid result: 
recall@5 : 0.3226    recall@10 : 0.3851    ndcg@5 : 0.2515    ndcg@10 : 0.2723
Mon 30 May 2022 05:16:08 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:17:40 INFO  epoch 3 training [time: 91.48s, train loss: 2059.6323]
Mon 30 May 2022 05:18:21 INFO  epoch 3 evaluating [time: 41.62s, valid_score: 0.273000]
Mon 30 May 2022 05:18:21 INFO  valid result: 
recall@5 : 0.3229    recall@10 : 0.3843    ndcg@5 : 0.2529    ndcg@10 : 0.273
Mon 30 May 2022 05:18:21 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:19:44 INFO  epoch 4 training [time: 82.26s, train loss: 2024.3325]
Mon 30 May 2022 05:20:27 INFO  epoch 4 evaluating [time: 43.37s, valid_score: 0.273700]
Mon 30 May 2022 05:20:27 INFO  valid result: 
recall@5 : 0.3213    recall@10 : 0.3892    ndcg@5 : 0.2511    ndcg@10 : 0.2737
Mon 30 May 2022 05:20:27 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:21:48 INFO  epoch 5 training [time: 80.80s, train loss: 2029.4788]
Mon 30 May 2022 05:22:29 INFO  epoch 5 evaluating [time: 40.76s, valid_score: 0.274200]
Mon 30 May 2022 05:22:29 INFO  valid result: 
recall@5 : 0.3245    recall@10 : 0.3877    ndcg@5 : 0.2534    ndcg@10 : 0.2742
Mon 30 May 2022 05:22:29 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:23:58 INFO  epoch 6 training [time: 89.54s, train loss: 1983.2883]
Mon 30 May 2022 05:24:51 INFO  epoch 6 evaluating [time: 52.62s, valid_score: 0.273800]
Mon 30 May 2022 05:24:51 INFO  valid result: 
recall@5 : 0.3248    recall@10 : 0.3868    ndcg@5 : 0.2535    ndcg@10 : 0.2738
Mon 30 May 2022 05:26:30 INFO  epoch 7 training [time: 99.15s, train loss: 1965.8530]
Mon 30 May 2022 05:27:21 INFO  epoch 7 evaluating [time: 50.51s, valid_score: 0.272800]
Mon 30 May 2022 05:27:21 INFO  valid result: 
recall@5 : 0.324    recall@10 : 0.3867    ndcg@5 : 0.2522    ndcg@10 : 0.2728
Mon 30 May 2022 05:28:52 INFO  epoch 8 training [time: 91.63s, train loss: 2010.5104]
Mon 30 May 2022 05:29:35 INFO  epoch 8 evaluating [time: 42.58s, valid_score: 0.276500]
Mon 30 May 2022 05:29:35 INFO  valid result: 
recall@5 : 0.3259    recall@10 : 0.3872    ndcg@5 : 0.2568    ndcg@10 : 0.2765
Mon 30 May 2022 05:29:35 INFO  Saving current: model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:31:05 INFO  epoch 9 training [time: 90.25s, train loss: 1969.8167]
Mon 30 May 2022 05:31:51 INFO  epoch 9 evaluating [time: 45.90s, valid_score: 0.275000]
Mon 30 May 2022 05:31:51 INFO  valid result: 
recall@5 : 0.323    recall@10 : 0.3885    ndcg@5 : 0.2536    ndcg@10 : 0.275
Mon 30 May 2022 05:33:36 INFO  epoch 10 training [time: 104.93s, train loss: 1948.4841]
Mon 30 May 2022 05:34:19 INFO  epoch 10 evaluating [time: 42.94s, valid_score: 0.274200]
Mon 30 May 2022 05:34:19 INFO  valid result: 
recall@5 : 0.3268    recall@10 : 0.3855    ndcg@5 : 0.2551    ndcg@10 : 0.2742
Mon 30 May 2022 05:35:53 INFO  epoch 11 training [time: 94.39s, train loss: 1983.3090]
Mon 30 May 2022 05:36:41 INFO  epoch 11 evaluating [time: 48.03s, valid_score: 0.272100]
Mon 30 May 2022 05:36:41 INFO  valid result: 
recall@5 : 0.325    recall@10 : 0.3868    ndcg@5 : 0.2519    ndcg@10 : 0.2721
Mon 30 May 2022 05:38:01 INFO  epoch 12 training [time: 79.33s, train loss: 1969.3071]
Mon 30 May 2022 05:38:43 INFO  epoch 12 evaluating [time: 41.90s, valid_score: 0.274600]
Mon 30 May 2022 05:38:43 INFO  valid result: 
recall@5 : 0.3248    recall@10 : 0.3879    ndcg@5 : 0.2538    ndcg@10 : 0.2746
Mon 30 May 2022 05:40:03 INFO  epoch 13 training [time: 80.08s, train loss: 1990.0292]
Mon 30 May 2022 05:40:47 INFO  epoch 13 evaluating [time: 44.68s, valid_score: 0.272500]
Mon 30 May 2022 05:40:47 INFO  valid result: 
recall@5 : 0.326    recall@10 : 0.3887    ndcg@5 : 0.252    ndcg@10 : 0.2725
Mon 30 May 2022 05:42:11 INFO  epoch 14 training [time: 83.66s, train loss: 1948.0927]
Mon 30 May 2022 05:42:48 INFO  epoch 14 evaluating [time: 37.35s, valid_score: 0.272100]
Mon 30 May 2022 05:42:48 INFO  valid result: 
recall@5 : 0.3199    recall@10 : 0.3872    ndcg@5 : 0.2501    ndcg@10 : 0.2721
Mon 30 May 2022 05:44:17 INFO  epoch 15 training [time: 88.66s, train loss: 1986.8636]
Mon 30 May 2022 05:45:02 INFO  epoch 15 evaluating [time: 45.05s, valid_score: 0.272300]
Mon 30 May 2022 05:45:02 INFO  valid result: 
recall@5 : 0.3248    recall@10 : 0.3875    ndcg@5 : 0.2516    ndcg@10 : 0.2723
Mon 30 May 2022 05:46:35 INFO  epoch 16 training [time: 92.65s, train loss: 1979.3444]
Mon 30 May 2022 05:47:28 INFO  epoch 16 evaluating [time: 53.02s, valid_score: 0.272100]
Mon 30 May 2022 05:47:28 INFO  valid result: 
recall@5 : 0.3245    recall@10 : 0.3852    ndcg@5 : 0.2526    ndcg@10 : 0.2721
Mon 30 May 2022 05:49:00 INFO  epoch 17 training [time: 91.79s, train loss: 1967.8548]
Mon 30 May 2022 05:49:39 INFO  epoch 17 evaluating [time: 39.31s, valid_score: 0.273800]
Mon 30 May 2022 05:49:39 INFO  valid result: 
recall@5 : 0.3254    recall@10 : 0.3888    ndcg@5 : 0.253    ndcg@10 : 0.2738
Mon 30 May 2022 05:51:05 INFO  epoch 18 training [time: 86.45s, train loss: 2000.4867]
Mon 30 May 2022 05:51:49 INFO  epoch 18 evaluating [time: 43.83s, valid_score: 0.272800]
Mon 30 May 2022 05:51:49 INFO  valid result: 
recall@5 : 0.3237    recall@10 : 0.3876    ndcg@5 : 0.2519    ndcg@10 : 0.2728
Mon 30 May 2022 05:53:28 INFO  epoch 19 training [time: 98.70s, train loss: 1957.1747]
Mon 30 May 2022 05:54:13 INFO  epoch 19 evaluating [time: 44.80s, valid_score: 0.273200]
Mon 30 May 2022 05:54:13 INFO  valid result: 
recall@5 : 0.3238    recall@10 : 0.3873    ndcg@5 : 0.2524    ndcg@10 : 0.2732
Mon 30 May 2022 05:54:13 INFO  Finished training, best eval result in epoch 8
Mon 30 May 2022 05:54:13 INFO  Loading model structure and parameters from model_saved/RecVAE-May-30-2022_05-09-30.pth
Mon 30 May 2022 05:54:59 INFO  best valid : OrderedDict([('recall@5', 0.3259), ('recall@10', 0.3872), ('ndcg@5', 0.2568), ('ndcg@10', 0.2765)])
Mon 30 May 2022 05:54:59 INFO  test result: OrderedDict([('recall@5', 0.3304), ('recall@10', 0.3947), ('ndcg@5', 0.2611), ('ndcg@10', 0.282)])
